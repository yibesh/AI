{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7fe9f72-4ca4-4a69-982c-b3e9efe03159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angle Rewards Summary:\n",
      "Angle: -90°, Total Reward: -27904.42\n",
      "Angle: -89°, Total Reward: 0.00\n",
      "Angle: -88°, Total Reward: -28501.72\n",
      "Angle: -87°, Total Reward: -27253.82\n",
      "Angle: -86°, Total Reward: -10181.13\n",
      "Angle: -85°, Total Reward: 0.00\n",
      "Angle: -84°, Total Reward: -9573.30\n",
      "Angle: -83°, Total Reward: -9154.73\n",
      "Angle: -82°, Total Reward: -36334.94\n",
      "Angle: -81°, Total Reward: 0.00\n",
      "Angle: -80°, Total Reward: -27940.41\n",
      "Angle: -79°, Total Reward: -17124.20\n",
      "Angle: -78°, Total Reward: -26782.19\n",
      "Angle: -77°, Total Reward: 0.00\n",
      "Angle: -76°, Total Reward: -17658.85\n",
      "Angle: -75°, Total Reward: -18285.66\n",
      "Angle: -74°, Total Reward: -33670.26\n",
      "Angle: -73°, Total Reward: -51354.32\n",
      "Angle: -72°, Total Reward: -16338.52\n",
      "Angle: -71°, Total Reward: 0.00\n",
      "Angle: -70°, Total Reward: -7746.96\n",
      "Angle: -69°, Total Reward: -46756.62\n",
      "Angle: -68°, Total Reward: 0.00\n",
      "Angle: -67°, Total Reward: -16464.09\n",
      "Angle: -66°, Total Reward: -15776.41\n",
      "Angle: -65°, Total Reward: -23098.92\n",
      "Angle: -64°, Total Reward: -28902.18\n",
      "Angle: -63°, Total Reward: -8772.67\n",
      "Angle: -62°, Total Reward: -32248.27\n",
      "Angle: -61°, Total Reward: -15439.46\n",
      "Angle: -60°, Total Reward: -10559.57\n",
      "Angle: -59°, Total Reward: -23287.95\n",
      "Angle: -58°, Total Reward: -14576.59\n",
      "Angle: -57°, Total Reward: -50312.15\n",
      "Angle: -56°, Total Reward: -6838.35\n",
      "Angle: -55°, Total Reward: -13295.87\n",
      "Angle: -54°, Total Reward: -27160.75\n",
      "Angle: -53°, Total Reward: -12557.57\n",
      "Angle: -52°, Total Reward: -5833.05\n",
      "Angle: -51°, Total Reward: -19486.95\n",
      "Angle: -50°, Total Reward: -24775.71\n",
      "Angle: -49°, Total Reward: 0.00\n",
      "Angle: -48°, Total Reward: -6271.07\n",
      "Angle: -47°, Total Reward: -13101.40\n",
      "Angle: -46°, Total Reward: -35895.68\n",
      "Angle: -45°, Total Reward: -12446.28\n",
      "Angle: -44°, Total Reward: -10696.86\n",
      "Angle: -43°, Total Reward: -11539.32\n",
      "Angle: -42°, Total Reward: -10452.57\n",
      "Angle: -41°, Total Reward: -6151.54\n",
      "Angle: -40°, Total Reward: -21754.26\n",
      "Angle: -39°, Total Reward: -11336.97\n",
      "Angle: -38°, Total Reward: -5973.67\n",
      "Angle: -37°, Total Reward: -23458.11\n",
      "Angle: -36°, Total Reward: -14840.63\n",
      "Angle: -35°, Total Reward: -4604.07\n",
      "Angle: -34°, Total Reward: -9497.68\n",
      "Angle: -33°, Total Reward: 0.00\n",
      "Angle: -32°, Total Reward: -14771.08\n",
      "Angle: -31°, Total Reward: -5201.51\n",
      "Angle: -30°, Total Reward: -13464.83\n",
      "Angle: -29°, Total Reward: -4694.44\n",
      "Angle: -28°, Total Reward: -17174.44\n",
      "Angle: -27°, Total Reward: -12813.74\n",
      "Angle: -26°, Total Reward: -4591.43\n",
      "Angle: -25°, Total Reward: 0.00\n",
      "Angle: -24°, Total Reward: -11730.77\n",
      "Angle: -23°, Total Reward: -4257.45\n",
      "Angle: -22°, Total Reward: 0.00\n",
      "Angle: -21°, Total Reward: -7911.83\n",
      "Angle: -20°, Total Reward: -7850.82\n",
      "Angle: -19°, Total Reward: -10408.78\n",
      "Angle: -18°, Total Reward: -17856.85\n",
      "Angle: -17°, Total Reward: -10476.47\n",
      "Angle: -16°, Total Reward: -6227.04\n",
      "Angle: -15°, Total Reward: 0.00\n",
      "Angle: -14°, Total Reward: -15729.69\n",
      "Angle: -13°, Total Reward: -11700.84\n",
      "Angle: -12°, Total Reward: -10102.30\n",
      "Angle: -11°, Total Reward: -10413.42\n",
      "Angle: -10°, Total Reward: -10145.97\n",
      "Angle: -9°, Total Reward: -6071.36\n",
      "Angle: -8°, Total Reward: 0.00\n",
      "Angle: -7°, Total Reward: -9714.74\n",
      "Angle: -6°, Total Reward: -3586.12\n",
      "Angle: -5°, Total Reward: -11960.77\n",
      "Angle: -4°, Total Reward: -3405.94\n",
      "Angle: -3°, Total Reward: -16505.31\n",
      "Angle: -2°, Total Reward: -19088.64\n",
      "Angle: -1°, Total Reward: -8690.75\n",
      "Angle: 0°, Total Reward: -20165.64\n",
      "Angle: 1°, Total Reward: -14579.05\n",
      "Angle: 2°, Total Reward: -9156.44\n",
      "Angle: 3°, Total Reward: -11926.88\n",
      "Angle: 4°, Total Reward: -7965.14\n",
      "Angle: 5°, Total Reward: -10035.57\n",
      "Angle: 6°, Total Reward: -8286.27\n",
      "Angle: 7°, Total Reward: 0.00\n",
      "Angle: 8°, Total Reward: -13452.50\n",
      "Angle: 9°, Total Reward: -7238.66\n",
      "Angle: 10°, Total Reward: -5780.32\n",
      "Angle: 11°, Total Reward: -3543.79\n",
      "Angle: 12°, Total Reward: -8664.27\n",
      "Angle: 13°, Total Reward: -12031.27\n",
      "Angle: 14°, Total Reward: -23356.46\n",
      "Angle: 15°, Total Reward: -6500.88\n",
      "Angle: 16°, Total Reward: -8040.74\n",
      "Angle: 17°, Total Reward: -17162.58\n",
      "Angle: 18°, Total Reward: -22807.86\n",
      "Angle: 19°, Total Reward: -2684.70\n",
      "Angle: 20°, Total Reward: 0.00\n",
      "Angle: 21°, Total Reward: 0.00\n",
      "Angle: 22°, Total Reward: 0.00\n",
      "Angle: 23°, Total Reward: -15518.89\n",
      "Angle: 24°, Total Reward: -4305.82\n",
      "Angle: 25°, Total Reward: -12014.44\n",
      "Angle: 26°, Total Reward: -11884.62\n",
      "Angle: 27°, Total Reward: -12019.12\n",
      "Angle: 28°, Total Reward: -23141.47\n",
      "Angle: 29°, Total Reward: -18768.46\n",
      "Angle: 30°, Total Reward: -5441.50\n",
      "Angle: 31°, Total Reward: -14759.96\n",
      "Angle: 32°, Total Reward: -15049.53\n",
      "Angle: 33°, Total Reward: -5100.50\n",
      "Angle: 34°, Total Reward: -5985.00\n",
      "Angle: 35°, Total Reward: -9526.82\n",
      "Angle: 36°, Total Reward: -26091.72\n",
      "Angle: 37°, Total Reward: -15639.80\n",
      "Angle: 38°, Total Reward: -11013.29\n",
      "Angle: 39°, Total Reward: -11570.99\n",
      "Angle: 40°, Total Reward: -6013.61\n",
      "Angle: 41°, Total Reward: -16990.35\n",
      "Angle: 42°, Total Reward: -12099.22\n",
      "Angle: 43°, Total Reward: -5872.57\n",
      "Angle: 44°, Total Reward: -5103.57\n",
      "Angle: 45°, Total Reward: -41952.83\n",
      "Angle: 46°, Total Reward: -16271.49\n",
      "Angle: 47°, Total Reward: -5686.31\n",
      "Angle: 48°, Total Reward: -12320.08\n",
      "Angle: 49°, Total Reward: -20731.20\n",
      "Angle: 50°, Total Reward: -13039.27\n",
      "Angle: 51°, Total Reward: -34409.35\n",
      "Angle: 52°, Total Reward: 0.00\n",
      "Angle: 53°, Total Reward: -46537.54\n",
      "Angle: 54°, Total Reward: -12628.38\n",
      "Angle: 55°, Total Reward: -42103.68\n",
      "Angle: 56°, Total Reward: -7556.04\n",
      "Angle: 57°, Total Reward: -23560.64\n",
      "Angle: 58°, Total Reward: -13277.66\n",
      "Angle: 59°, Total Reward: -27858.41\n",
      "Angle: 60°, Total Reward: -15605.12\n",
      "Angle: 61°, Total Reward: -8563.66\n",
      "Angle: 62°, Total Reward: -15274.13\n",
      "Angle: 63°, Total Reward: 0.00\n",
      "Angle: 64°, Total Reward: -45440.92\n",
      "Angle: 65°, Total Reward: -23336.27\n",
      "Angle: 66°, Total Reward: -16348.88\n",
      "Angle: 67°, Total Reward: -7697.20\n",
      "Angle: 68°, Total Reward: -8100.99\n",
      "Angle: 69°, Total Reward: -25499.04\n",
      "Angle: 70°, Total Reward: -17721.19\n",
      "Angle: 71°, Total Reward: -9312.59\n",
      "Angle: 72°, Total Reward: -9413.25\n",
      "Angle: 73°, Total Reward: -86141.41\n",
      "Angle: 74°, Total Reward: -9674.73\n",
      "Angle: 75°, Total Reward: -17550.35\n",
      "Angle: 76°, Total Reward: -51793.57\n",
      "Angle: 77°, Total Reward: -9037.49\n",
      "Angle: 78°, Total Reward: -17258.22\n",
      "Angle: 79°, Total Reward: -35708.61\n",
      "Angle: 80°, Total Reward: -18057.41\n",
      "Angle: 81°, Total Reward: -8732.93\n",
      "Angle: 82°, Total Reward: -9028.83\n",
      "Angle: 83°, Total Reward: -9519.86\n",
      "Angle: 84°, Total Reward: -38025.79\n",
      "Angle: 85°, Total Reward: -8903.88\n",
      "Angle: 86°, Total Reward: -19696.36\n",
      "Angle: 87°, Total Reward: -18602.58\n",
      "Angle: 88°, Total Reward: -18752.65\n",
      "Angle: 89°, Total Reward: -18902.13\n",
      "Angle: 90°, Total Reward: -9437.05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Step 1: Define the environment\n",
    "class AntennaArrayEnvironment:\n",
    "    def __init__(self, angle_range=(-90, 90), snr_target=20):\n",
    "        self.angle_range = angle_range  # Range of angles (degrees)\n",
    "        self.snr_target = snr_target  # Target Signal-to-Noise Ratio (SNR)\n",
    "        self.current_angle = 0  # Initial angle\n",
    "        self.interference = random.uniform(5, 15)  # Random interference\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_angle = random.uniform(*self.angle_range)\n",
    "        self.interference = random.uniform(5, 15)\n",
    "        return self.current_angle, self.interference\n",
    "\n",
    "    def step(self, action):\n",
    "        # Action: -1 (decrease angle), 0 (no change), 1 (increase angle)\n",
    "        angle_adjustment = action - 1  # Map action {0,1,2} to {-1, 0, +1}\n",
    "        self.current_angle = np.clip(self.current_angle + angle_adjustment, *self.angle_range)\n",
    "        \n",
    "        # Simulate SNR based on current angle\n",
    "        snr = self.snr_target - abs(self.current_angle) + random.uniform(-1, 1) - self.interference\n",
    "        \n",
    "        # Reward: Higher SNR gets a better reward\n",
    "        reward = snr - self.snr_target if snr >= self.snr_target else -abs(self.snr_target - snr)\n",
    "        \n",
    "        # Termination condition\n",
    "        done = abs(snr - self.snr_target) < 0.5\n",
    "        \n",
    "        return (self.current_angle, self.interference), reward, done\n",
    "\n",
    "# Step 2: Define the Q-Learning agent\n",
    "class QLearningAgent:\n",
    "    def __init__(self, state_space, action_space, learning_rate=0.1, discount_factor=0.99, exploration_rate=1.0, exploration_decay=0.99):\n",
    "        self.state_space = state_space\n",
    "        self.action_space = action_space\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.exploration_rate = exploration_rate\n",
    "        self.exploration_decay = exploration_decay\n",
    "        self.q_table = np.zeros((state_space, action_space))\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        if random.uniform(0, 1) < self.exploration_rate:\n",
    "            return random.randint(0, self.action_space - 1)\n",
    "        return np.argmax(self.q_table[state])\n",
    "\n",
    "    def update_q_value(self, state, action, reward, next_state):\n",
    "        best_next_action = np.argmax(self.q_table[next_state])\n",
    "        td_target = reward + self.discount_factor * self.q_table[next_state, best_next_action]\n",
    "        self.q_table[state, action] += self.learning_rate * (td_target - self.q_table[state, action])\n",
    "\n",
    "    def decay_exploration(self):\n",
    "        self.exploration_rate *= self.exploration_decay\n",
    "\n",
    "# Step 3: Train the agent and track rewards for each angle\n",
    "env = AntennaArrayEnvironment()\n",
    "agent = QLearningAgent(state_space=180, action_space=3)\n",
    "\n",
    "episodes = 500\n",
    "angle_rewards = {angle: 0 for angle in range(-90, 91)}  # Dictionary to track rewards for each angle\n",
    "\n",
    "for episode in range(episodes):\n",
    "    state, _ = env.reset()\n",
    "    state = int(np.clip(state + 90, 0, 179))  # Map angle to index and clip within bounds\n",
    "    total_reward = 0\n",
    "\n",
    "    for _ in range(100):  # Limit steps per episode\n",
    "        action = agent.choose_action(state)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        next_state = int(np.clip(next_state[0] + 90, 0, 179))  # Map angle to index and clip within bounds\n",
    "\n",
    "        agent.update_q_value(state, action, reward, next_state)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # Track total rewards per angle\n",
    "    int_angle = int(np.round(env.current_angle))  # Convert to nearest integer\n",
    "    angle_rewards[int_angle] += total_reward\n",
    "    agent.decay_exploration()\n",
    "\n",
    "# Step 4: Display rewards for each angle\n",
    "print(\"Angle Rewards Summary:\")\n",
    "for angle, reward in sorted(angle_rewards.items()):\n",
    "    print(f\"Angle: {angle}°, Total Reward: {reward:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e59462e-ba89-458c-80ce-0dd354089d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
